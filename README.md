# RPG Rules Assistant

This project is an AI-enhanced rules assistant for tabletop RPGs. It enables players and game masters to semantically search through RPG PDFs and ask AI-powered questions about the rules. The assistant uses ChromaDB for document retrieval and a quantized LLaMA-2 model (run locally) for natural language understanding.

---

## ğŸš€ Features

- ğŸ” **Semantic Search**: Query embedded RPG rulebooks using ChromaDB and SentenceTransformers.
- ğŸ¤– **AI-Powered Responses**: Get contextual answers grounded in actual rulebooks using a local LLaMA-2 model.
- ğŸ“„ **PDF Ingestion**: Converts, chunks, and embeds PDFs using Markdown conversion and sentence embeddings.
- ğŸ§  **Local LLM Integration**: Hugging Face Transformers with 4-bit quantized LLaMA-2.
- ğŸŒ **FastAPI Backend**: Clean, modular Python API for integration and use.
- ğŸ§ª **Makefile Convenience**: Includes Makefile shortcuts for local development and processing.

---

## ğŸ§± Tech Stack

| Component         | Tech                                        |
|------------------|---------------------------------------------|
| API Framework     | FastAPI                                     |
| Embedding Model   | `sentence-transformers/all-MiniLM-L6-v2`    |
| Vector DB         | ChromaDB (persistent local storage)         |
| LLM               | LLaMA-2-13B-chat (4-bit, Hugging Face)      |
| Markdown Parsing  | `markitdown` (Microsoft PDF converter)      |

---

## ğŸ—‚ Folder Structure

```
project-root/
â”œâ”€â”€ ai_gm_assistant/       # Core logic for PDF processing, retrieval, and LLM interface
â”‚   â”œâ”€â”€ hf_integration.py  # Loads and queries LLaMA-2 model
â”‚   â”œâ”€â”€ main.py            # FastAPI entrypoint
â”‚   â”œâ”€â”€ retriever.py       # ChromaDB and embedding logic
â”‚   â””â”€â”€ process_pdfs.py    # PDF ingestion, markdown conversion, chunking
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/              # Place your RPG PDFs here
â”‚   â””â”€â”€ rpg_sources_db/    # ChromaDB persistent storage
â”œâ”€â”€ env.clean              # Sample environment variables (rename to `.env`)
â”œâ”€â”€ Makefile               # Developer shortcuts
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”‘ Setup Instructions

### 1. Environment Variables

Copy `env.clean` to `.env` before running anything:

```bash
cp env.clean .env
```

Ensure the `.env` includes values like:

- `CHROMA_INDEX_PATH=./data/rpg_sources_db`
- `EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2`
- `RETRIEVAL_RESULTS=8`
- `ALLOWED_ORIGINS=http://localhost:5173`

### 2. Hugging Face Authentication

If you're using gated models (like `meta-llama/Llama-2-13b-chat-hf`), you **must be authenticated with Hugging Face**. There are two options:

- Login via CLI:
  ```bash
  huggingface-cli login
  ```
- Or set the environment variable in your `.env`:
  ```env
  HF_TOKEN=your_huggingface_token
  ```

The code expects access to Hugging Face via `use_auth_token=True`.

---


## ğŸ§ª API Endpoints

| Method | Endpoint         | Description                         |
|--------|------------------|-------------------------------------|
| GET    | `/search`        | Returns semantic matches from ChromaDB |
| GET    | `/ai-search`     | Retrieves + answers with context-grounded LLM |
| GET    | `/ai-direct`     | Sends query to the LLM with no external context |

---

## ğŸ’¬ Example Queries

- "How does weather affect overland travel?"
- "What are the rules for grappling?"
- "Can you flank an enemy in difficult terrain?"

---

## ğŸ“œ License

Apache 2.0

---

## ğŸ™Œ Credits

Built by [Su Soloway](https://www.linkedin.com/in/...) and [Oluf Andrews](https://www.linkedin.com/in/...) using FastAPI, ChromaDB, and Hugging Face Transformers.